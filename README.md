# Introduction
This package provides an analytic for hypothesis testing that 2 Recommender systems are functionally related. The package makes use of the RBO (Rank Biased Overlap) scoring function developed by [researchers](https://dl.acm.org/doi/10.1145/1852102.1852106) from the University of Melbourne.

# How to install the package
1. clone this repository
2. using either pip or preferably uv install the package into your python environment like so:
```bash
cd rbo-analytics

# using uv
uv pip install .

# or using pip
pip install .
```

# How to use the package

## Statistically testing the relationship between 2 ranked lists
If you have 2 ranked lists of length $K$ produced by recommenders A and B and recommender A  provides a probability distribution for its list, then you can perform hypothesis testing that the list generated by recommender B is related to the list generated by recommender A like so:

```python
import rbo_analytics

# decide desired p-value cutoff for determining the validity of the null hypothesis/alternative hypothesis
pcutoff = .01

num_simulations = int(100/pcutoff+0.5) # want enough monte carlo simulations for accuracy.

# K determines how many of the ranked entries of list_a are important. If all matter, then K = len(list_a)
p = 0.01**(1/K) # persistence parameter for RBO scores.

# perform simulations
montecarlo_scores = rbo_analytics(probs,K = K,T=num_simulations,verbose=True)

cutoff_value = montecarlo_scores[100] # This is bottom %pcutoff of the generated scores.

rboscore = rbo_analytics.compute_rbo_score(list_a, list_b,p)

# Null hypothesis: the 2 ranked lists **are** related.
null_hypothesis_is_true = (rboscore > cutoff_value)
```
## Comparing document embedding models

* We have 2 different document embedding models, A & B. 
* We have a corpus of $N \gg 1$ documents. 

We would like to know if the 2 embedding models are statistically functionally related.

### Solution: 

1. For each document $D_n$ compute its corresponding vector embedding $E_n := A(D_n)$, $F_n = B(D_n)$.
2. For embedding model $A$ determine an appropriate value of $K$ as follows:
   1. Randomly select  $M \gg 1$ documents $\{D_m\}$ from the corpus. Let $\{E_m\}$ denote their corresponding vector embeddings.
   2. For each vector $E_m$ find its $P \ge 100$ closest neighbors $\{E_{m,p}\}$. **Exclude** $E_m$ from the list of neighbors. Compute the cosine similarity between vector $E_m$ and its $P$ closest neighors: $(<E_m,E_{m,p}>)$.
   3. Sort the cosine similarities as an ascending sequence $(cos_p)$.
   4. Find the elbow in the sequence of cosines $(cos_p)$ using an F-test to split the sequence into 2 subsequences. The size of the second subsequence is the corresponding value of $K_m$.
   5. We can either take $K= \max(\{K_m\})$ or keep the set of $K$ values $\{K_m\}$.
3. Now that we have a value of $K$ for each document $D_m$ we have a corresponding persistence parameter $p=0.01^{(1/K)}$.
4. For each document $D_m$ we have a ranked list of $K$ documents $list\_a = (i_1,\ldots,i_K)$ where $i_k$ denotes the index of the document that is $k^{th}$ closes to $D_m$   according to model $A$. We generate a similar second list of K ranked documents $list\_b = (j_1,\ldots, j_K)$ by proximity according to model $B$ (look at the corresponding vectors $(F_n)$.) For a corresponding probality distribution for model A's ranked list, we use the geometric based sequence 
$$prob = \frac{(1-p)}{1-p^{K}}\times (1,p,p**2, \ldots, p_{K-1})$$
5. Now we can use the rbo_analytics compute_recommender_test_statistic function to perform hypothesis testing.
```python
import rbo_analytics
Z = rbo_analytics.compute_recommender_test_statistic((lists_a, lists_b,probs,verbose=True)

print("Sigmage that the 2 document embedders are functionally related: {Z}")
print(f"The 2 document embedders are functionally related: {Z>=-2.33}")
```

## Comparing Nonlinear Projection Algorithm
One of the first things I wanted to do after developing a hypothesis testing analytic with RBO waas to
compare the performance of my favorite local structure preserving nonlinear projection algorithm [UMAP](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Uniform_manifold_approximation_and_projection) and an
alternative algorithm [PACMAP](https://github.com/YingfanWang/PaCMAP).

The idea is similar to how one can compare document embedder maps:

* Take a high dimensional data set $D\subset \mathbb{R}^P$ with $P \gg 1$.
* Select a target dimension $Q \ll P$ to project down to.
* Project the data down to $X = UMAP(D) \subset \mathbb{R}^Q$ and $Y = PACMAP(D) \subset \mathbb{R}^Q$

